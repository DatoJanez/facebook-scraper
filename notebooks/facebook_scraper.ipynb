{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facebook-scraper",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVkz3o50IMcB",
        "cellView": "form"
      },
      "source": [
        "#@title Default title text\n",
        "pages = \"\" #@param {type:\"string\"}\n",
        "days =  #@param {type:\"integer\"}\n",
        "filter = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not os.path.isdir('/content/facebook-scraper'):\n",
        "    !git clone https://github.com/DatoJanez/facebook-scraper &> /dev/null\n",
        "\n",
        "%cd /content/facebook-scraper\n",
        "# !pip install facebook-scraper &> /dev/null\n",
        "!pip install requests_html dateparser &> /dev/null\n",
        "\n",
        "if not pages or days == 0:\n",
        "    print('No page id') \n",
        "\n",
        "pages = pages.split(' ')\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import os.path\n",
        "from datetime import datetime\n",
        "\n",
        "df_initial = pd.DataFrame(columns=['page_id', 'post_id', 'text', 'post_text', 'shared_text', 'time', 'image', 'video',\n",
        "       'video_thumbnail', 'video_id', 'likes', 'comments', 'shares',\n",
        "       'post_url', 'link', 'user_id', 'images'])\n",
        "\n",
        "df_initial.to_csv('all_posts.csv', index=None)\n",
        "\n",
        "for page_id in tqdm(pages):\n",
        "    !python facebook_scraper --filename {page_id}.csv --pages 100000 -d {days} {page_id} &> /dev/null \n",
        "    # !facebook-scraper --filename {page_id}.csv --pages {pages} {page_id} &> /dev/null\n",
        "\n",
        "    if not os.path.isfile('{}.csv'.format(page_id)):\n",
        "        continue\n",
        "        \n",
        "    df = pd.read_csv('{}.csv'.format(page_id), index_col=None)\n",
        "    df = df[pd.notna(df.text) & df.text.str.contains(r'{}'.format(filter))]\n",
        "    \n",
        "    df[\"page_id\"] = page_id\n",
        "\n",
        "    df_all_posts = pd.read_csv('all_posts.csv', index_col=None)\n",
        "    \n",
        "    pd.concat([df_all_posts, df]).to_csv('all_posts.csv', index=None)\n",
        "\n",
        "    !rm {page_id}.csv\n",
        "    \n",
        "from IPython.display import HTML\n",
        "import base64\n",
        "\n",
        "def create_download_link( title = \"Download the collected data\", filename = \"fb-data-{}.csv\".format(datetime.now().strftime('%Y-%m-%d-%H-%M'))):  \n",
        "    df_all_posts = pd.read_csv('all_posts.csv', index_col=None)\n",
        "    csv = df_all_posts.to_csv()\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "create_download_link()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}